{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import pinecone\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT HTE DATA FROM PDF\n",
    "def load_pdf(data):\n",
    "    loader=DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "\n",
    "    documents=loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"/Users/piyushpandey955/Desktop/AIML/gen ai/medical chatbot project/Medical-Chatbot/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=20)\n",
    "    text_chunks=text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of my chunk: 3896\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"length of my chunk:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download embedding model\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result=embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone\n",
    "import os\n",
    "\n",
    "os.environ['PINECONE_API_KEY'] = PINECONE_API_KEY\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index_name = 'bhagwat-gita'\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "#creating embeddings for each of the text chunks and storing\n",
    "docsearch=PineconeVectorStore.from_texts([t.page_content for t in text_chunks], embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='senses:\\tvoice,\\tlegs,\\thands,\\tthe\\tanus\\tand\\tthe\\tgenitals.\\tThen,\\tabove\\tthe\\tsenses,\\nthere\\tis\\tthe\\tmind,\\twhich\\tis\\twithin\\tand\\twhich\\tcan\\tbe\\tcalled\\tthe\\tsense\\twithin.\\nTherefore,\\tincluding\\tthe\\tmind,\\tthere\\tare\\televen\\tsenses\\taltogether.\\tThen\\tthere\\nare\\t the\\t five\\t objects\\t of\\t the\\t senses:\\t smell,\\t taste,\\t warmth,\\t touch\\t and\\t sound.\\nNow\\t the\\t aggregate\\t of\\t these\\t twenty-four\\t elements\\t is\\t called\\t the\\t field\\t of\\nactivity.\\tIf\\tone\\tmakes\\tan\\tanalytical\\tstudy\\tof\\tthese\\ttwenty-four\\tsubjects,\\tthen'), Document(page_content=\"material\\t bodily\\t concept.\\t In\\t the\\t bodily\\t conception\\t of\\t life\\t thereare\\t specific\\nduties\\t for\\t the\\t brāhmaṇas\\t and\\t kṣatriyas\\t respectively,\\t and\\t such\\t duties\\t are\\nunavoidable.\\t Svadharma\\tis\\tordained\\tby\\tthe\\tLord,\\tand\\tthis\\twill\\tbe\\tclarified\\nin\\tthe\\tFourth\\tChapter.\\tOn\\tthe\\tbodily\\tplane\\tsvadharma\\tis\\tcalled\\tvarṇāśrama-\\ndharma,\\t or\\t man's\\t steppingstone\\t for\\t spiritual\\t understanding.\\t Human\\ncivilization\\tbegins\\tfrom\\tthe\\tstage\\tof\\t varṇāśrama-dharma,\\tor\\tspecific\\tduties\"), Document(page_content='bodily\\tmovement\\tare\\temanating\\tfrom\\tthis\\tpart\\tof\\tthe\\tbody.\\tThe\\tcorpuscles\\nwhich\\tcarry\\tthe\\toxygen\\tfrom\\tthe\\tlungs\\tgather\\tenergy\\tfrom\\tthe\\tsoul.\\tWhen\\nthe\\t soul\\t passes\\t away\\t from\\t this\\t position,\\t activity\\t of\\t the\\t blood,\\t generating\\nfusion,\\t ceases.\\t Medical\\t science\\t accepts\\t the\\t importance\\t of\\t the\\t red\\ncorpuscles,\\tbut\\tit\\tcannot\\tascertain\\tthat\\tthe\\tsource\\tof\\tthe\\tenergy\\tis\\tthe\\tsoul.\\nMedical\\t science,\\t however,\\t does\\t admit\\t that\\t the\\t heart\\t is\\t the\\t seat\\t of\\t all\\nenergies\\tof\\tthe\\tbody.')]\n"
     ]
    }
   ],
   "source": [
    "query=\"Who is Arjuna?\"\n",
    "docs=docsearch.similarity_search(query,k=3)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer ,just say that you don't know ,don't try to makeup an answer.\n",
    "\n",
    "Context:{context}\n",
    "Question:{question}\n",
    "\n",
    "Only return the helpful answer below and nothing else\n",
    "\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "chain_type_kwargs={\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=CTransformers(model=\"/Users/piyushpandey955/Desktop/AIML/gen ai/medical chatbot project/Medical-Chatbot/model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "                  model_type=\"llama\",\n",
    "                  config={'max_new_tokens':512,\n",
    "                          'temperature':0.8}\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "\n",
    "# Use the Pinecone vectorstore from Langchain\n",
    "vectorstore = Pinecone(\n",
    "    index=pinecone.Index(index_name, host='https://bhagwat-gita-9d82pte.svc.aped-4627-b74a.pinecone.io'),\n",
    "    embedding_function=embeddings.embed_query,\n",
    "    text_key=\"text\"\n",
    "    )\n",
    "\n",
    "# Set up the retriever with Pinecone and Langchain\n",
    "retriever = vectorstore.as_retriever(search_kwargs={'k': 2})\n",
    "\n",
    "qa=RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever,\n",
    "    return_source_documents=True, \n",
    "    chain_type_kwargs=chain_type_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"who is Duryodhana?\"\n",
    "query_embedding = embeddings.embed_query(user_input)\n",
    "len(query_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match: rasanaṁ\tghrāṇam\teva\tca\n",
      "adhiṣṭhāya\tmanaś\tcāyaṁ\n",
      "viṣayān\tupasevate\n",
      "śrotram—ears;\t cakṣuḥ—eyes;\t sparśanam—touch;\t ca—also;\t rasanam—\n",
      "tongue;\t ghrāṇam—smelling\tpower;\t eva—also;\t ca—and;\t adhiṣṭhāya—being\n",
      "situated;\t manaḥ—mind;\t ca—also;\t ayam—this;\t viṣayān—sense\t objects;\n",
      "upasevate—enjoys.\n",
      "TRANSLATION\n",
      "The\tliving\tentity,\tthus\ttaking\tanother\tgross\tbody,\tobtains\ta\tcertain\n",
      "type\t of\t ear,\t tongue,\t and\t nose\t and\t sense\t of\t touch,\t which\t are\t grouped\n",
      "Match: anus\t and\t the\t genital.\t The\t living\t entity\t in\t his\t conditioned\t stage\t identifies\n",
      "himself\twith\tthe\tbody,\tbut\twhen\the\tidentifies\thimself\twith\tthe\tLord\twithin\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Query Pinecone using the keyword arguments format\n",
    "result = index.query(vector=query_embedding, top_k=2, include_metadata=True)\n",
    "\n",
    "# Check if results are found\n",
    "if result and 'matches' in result:\n",
    "    # Loop through the top results\n",
    "    for match in result['matches']:\n",
    "        # Extract metadata if available (assuming text is stored in metadata)\n",
    "        if 'metadata' in match and 'text' in match['metadata']:\n",
    "            # Extract and print the relevant text\n",
    "            print(\"Match:\", match['metadata']['text'])\n",
    "        else:\n",
    "            print(\"No metadata or text field found in this match.\")\n",
    "else:\n",
    "    print(\"No results found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
